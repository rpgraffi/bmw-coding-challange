{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import instructor\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from src.services.core.messages_service import MessagesService\n",
    "\n",
    "load_dotenv()\n",
    "client = instructor.patch(OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'system', 'content': 'You are an assistant that helps users find sushi restaurants and parking spots in Munich. \\nWhen a user expresses interest in either sushi, parking, or both:\\n1. Use the set_user_interest function to record their preference\\n2. Provide relevant parking or restaurant information\\n3. ALWAYS respond with a natural language message summarizing the information for the user\\n'}\n",
      "{'role': 'user', 'content': 'Hey'}\n"
     ]
    }
   ],
   "source": [
    "# Initialize vars\n",
    "messages_service = MessagesService()\n",
    "openai_model = \"gpt-3.5-turbo\"\n",
    "user_interest_enum = None\n",
    "\n",
    "# Initial system message\n",
    "system_prompt = \"\"\"You are an assistant that helps users find sushi restaurants and parking spots in Munich. \n",
    "When a user expresses interest in either sushi, parking, or both:\n",
    "1. Use the set_user_interest function to record their preference\n",
    "2. Provide relevant parking or restaurant information\n",
    "3. ALWAYS respond with a natural language message summarizing the information for the user\n",
    "\"\"\"\n",
    "\n",
    "messages_service.add_system_message(system_prompt)\n",
    "\n",
    "user_prompt = \"I want to park my car\"\n",
    "user_prompt = \"I want to eat sushi\"\n",
    "# user_prompt = \"I want to park my car and eat sushi\"\n",
    "# user_prompt = input(\"eg. I am looking for a Sushi Restaurant in Munich.\")\n",
    "user_prompt = \"Hey\"\n",
    "\n",
    "messages_service.add_user_message(user_prompt)\n",
    "messages_service.print_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'system', 'content': 'You are an assistant that helps users find sushi restaurants and parking spots in Munich. \\nWhen a user expresses interest in either sushi, parking, or both:\\n1. Use the set_user_interest function to record their preference\\n2. Provide relevant parking or restaurant information\\n3. ALWAYS respond with a natural language message summarizing the information for the user\\n'}\n",
      "{'role': 'user', 'content': 'Hey'}\n",
      "{'role': 'assistant', 'content': 'Hello! How can I assist you today? Are you looking for sushi restaurants, parking spots, or both in Munich?'}\n",
      "{'role': 'function', 'name': 'UserInterestIntent', 'content': <UserInterestEnum.ASSISTANT: 'ASSISTANT'>}\n"
     ]
    }
   ],
   "source": [
    "from src.models.intent.user_interest_intent import UserInterestIntent\n",
    "\n",
    "# Get user interest\n",
    "intent : UserInterestIntent = client.chat.completions.create(\n",
    "    model=openai_model,\n",
    "    messages=messages_service.get_messages(),\n",
    "    response_model=UserInterestIntent,\n",
    ")\n",
    "\n",
    "messages_service.add_assistant_message(intent.assistant_message)\n",
    "messages_service.add_function_message(UserInterestIntent.__name__, intent.interest)\n",
    "\n",
    "user_interest_enum = intent.interest\n",
    "\n",
    "messages_service.print_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_prompt = \"List all parking spots\"\n",
    "user_prompt = \"How can i pay for parking?\"\n",
    "user_prompt = \"Where can i eat german sushi?\"\n",
    "user_prompt = \"Tell a joke\"\n",
    "messages_service.add_user_message(user_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose response format based on user intend\n",
    "Its either Parking or Sushi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'assistant', 'content': 'I believe a good joke about sushi might lift your spirits! Why did the sushi blush? Because it saw the seaweed!'}\n",
      "{'role': 'function', 'name': 'AssistantModel', 'content': '{\"assistant_message\":\"I believe a good joke about sushi might lift your spirits! Why did the sushi blush? Because it saw the seaweed!\"}'}\n"
     ]
    }
   ],
   "source": [
    "from src.services.user.user_interest_service import get_user_interest\n",
    "\n",
    "response_model, intent_service = get_user_interest(user_interest_enum)\n",
    "\n",
    "intent = client.chat.completions.create(\n",
    "    model=openai_model,\n",
    "    messages=messages_service.get_messages(),\n",
    "    response_model=response_model,\n",
    ")\n",
    "\n",
    "messages_service.add_assistant_message(intent.assistant_message)\n",
    "messages_service.print_last_message()\n",
    "messages_service.add_function_message(intent.__class__.__name__, intent)\n",
    "messages_service.print_last_message()\n",
    "\n",
    "if intent_service is not None:\n",
    "    result = intent_service.handle_intent(intent)\n",
    "    messages_service.add_function_message(intent_service.handle_intent.__name__, result)\n",
    "    messages_service.print_last_message()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'assistant', 'content': 'I believe a good joke about sushi might lift your spirits! Why did the sushi blush? Because it saw the seaweed!'}\n"
     ]
    }
   ],
   "source": [
    "from src.models.intent.assistant_model import AssistantModel\n",
    "\n",
    "response : AssistantModel = client.chat.completions.create(\n",
    "    model=openai_model,\n",
    "    messages=messages_service.get_messages(),\n",
    "    response_model=AssistantModel,\n",
    ")\n",
    "\n",
    "messages_service.add_assistant_message(response.assistant_message)\n",
    "messages_service.print_last_message()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use it like a chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'user', 'content': ''}\n",
      "{'role': 'assistant', 'content': 'I believe a good joke about sushi might lift your spirits! Why did the sushi blush? Because it saw the seaweed!'}\n",
      "{'role': 'function', 'name': 'UserInterestIntent', 'content': <UserInterestEnum.ASSISTANT: 'ASSISTANT'>}\n",
      "{'role': 'function', 'name': 'AssistantModel', 'content': '{\"assistant_message\":\"It seems like you might be interested in sushi or parking. How can I assist you today?\"}'}\n"
     ]
    }
   ],
   "source": [
    "from src.models.intent.user_interest_intent import UserInterestIntent\n",
    "\n",
    "for i in range(2):\n",
    "    \n",
    "    # get user input\n",
    "    user_prompt = input(\"User: \")\n",
    "    messages_service.add_user_message(user_prompt)\n",
    "    messages_service.print_last_message()\n",
    "\n",
    "\n",
    "    # Get user interest each time to shrink down the response models\n",
    "    intent : UserInterestIntent = client.chat.completions.create(\n",
    "        model=openai_model,\n",
    "        messages=messages_service.get_messages(),\n",
    "        response_model=UserInterestIntent,\n",
    "    )\n",
    "\n",
    "    messages_service.add_assistant_message(intent.assistant_message)\n",
    "    messages_service.print_last_message()\n",
    "    messages_service.add_function_message(UserInterestIntent.__name__, intent.interest)\n",
    "    messages_service.print_last_message()\n",
    "\n",
    "    user_interest_enum = intent.interest\n",
    "    response_model, intent_service = get_user_interest(user_interest_enum)\n",
    "\n",
    "    # get user intent\n",
    "    intent = client.chat.completions.create(\n",
    "        model=openai_model,\n",
    "        messages=messages_service.get_messages(),\n",
    "        response_model=response_model,\n",
    "    )\n",
    "\n",
    "    messages_service.add_function_message(intent.__class__.__name__, intent)\n",
    "    messages_service.print_last_message()\n",
    "\n",
    "    \n",
    "    # handle intent\n",
    "    if intent_service is not None:\n",
    "        result = intent_service.handle_intent(intent)\n",
    "        messages_service.add_function_message(intent_service.handle_intent.__name__, result)\n",
    "        messages_service.print_last_message()\n",
    "\n",
    "        # Assistant help to summarize the data\n",
    "        response = client.chat.completions.create(\n",
    "            model=openai_model,\n",
    "            messages=messages_service.get_messages(),\n",
    "            response_model=AssistantModel,\n",
    "        )\n",
    "\n",
    "        messages_service.add_assistant_message(response.assistant_message)\n",
    "        messages_service.print_last_message()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset jupiter kernel\n",
    "# %reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
